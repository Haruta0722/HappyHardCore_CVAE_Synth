import tensorflow as tf
from model import TimeWiseCVAE
import numpy as np
from create_datasets import make_dataset_from_synth_csv


class AntiCollapseCVAE(TimeWiseCVAE):
    """
    Posterior Collapseã‚’é˜²ããŸã‚ã®æ‹¡å¼µç‰ˆCVAE
    """

    def __init__(self, steps_per_epoch=87, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # â˜…é‡è¦: ã‚¨ãƒãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
        self.steps_per_epoch = steps_per_epoch

        # å­¦ç¿’æˆ¦ç•¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆã‚¨ãƒãƒƒã‚¯å˜ä½ï¼‰
        self.kl_warmup_epochs = 20
        self.kl_rampup_epochs = 50
        self.kl_warmup_steps = self.kl_warmup_epochs * steps_per_epoch
        self.kl_rampup_steps = self.kl_rampup_epochs * steps_per_epoch

        self.kl_target = 0.001  # ç›®æ¨™KLé‡ã¿ï¼ˆã‚ˆã‚Šå°ã•ãï¼‰
        self.free_bits = 0.5  # å„æ¬¡å…ƒã®æœ€å°æƒ…å ±é‡ï¼ˆnatsï¼‰

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½è·¡ç”¨
        self.z_std_ema = tf.Variable(1.0, trainable=False)  # æŒ‡æ•°ç§»å‹•å¹³å‡

    def compute_kl_weight_with_warmup(self):
        """
        æ®µéšçš„ã«KLæå¤±ã‚’å°å…¥
        """
        step = tf.cast(self.optimizer.iterations, tf.float32)

        # Phase 1 (0-10000): KL=0
        # Phase 2 (10000-30000): 0 â†’ target
        # Phase 3 (30000+): target

        warmup_progress = (step - self.kl_warmup_steps) / 20000.0
        warmup_progress = tf.clip_by_value(warmup_progress, 0.0, 1.0)

        return self.kl_target * warmup_progress

    def compute_free_bits_kl(self, z_mean, z_logvar):
        """
        Free Bits: å„æ¬¡å…ƒã§æœ€ä½é™ã®æƒ…å ±é‡ã‚’ä¿è¨¼
        """
        # æ¬¡å…ƒã”ã¨ã®KL
        kl_per_dim = -0.5 * (
            1 + z_logvar - tf.square(z_mean) - tf.exp(z_logvar)
        )

        # å„æ¬¡å…ƒã§ free_bits ä»¥ä¸Šã‚’å¼·åˆ¶
        kl_clamped = tf.maximum(kl_per_dim, self.free_bits)

        return tf.reduce_mean(kl_clamped)

    def add_gaussian_noise_to_z(self, z, noise_scale=0.1):
        """
        å­¦ç¿’ä¸­ã«zã«ãƒã‚¤ã‚ºã‚’è¿½åŠ ã—ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’é ‘å¼·ã«ã™ã‚‹
        """
        noise = tf.random.normal(tf.shape(z), stddev=noise_scale)
        return z + noise

    def train_step(self, data):
        x, cond = data

        with tf.GradientTape() as tape:
            z_mean, z_logvar = self.encoder([x, cond])
            z = self.sample_z(z_mean, z_logvar)

            # â˜…å¯¾ç­–1: å­¦ç¿’ä¸­ã«zã«ãƒã‚¤ã‚ºã‚’è¿½åŠ 
            # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãŒzã®å°ã•ãªå¤‰åŒ–ã«ã‚‚å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
            z_noisy = self.add_gaussian_noise_to_z(z, noise_scale=0.05)

            # å‘¨æ³¢æ•°ç‰¹å¾´ã‚’ç”Ÿæˆ
            from model import generate_frequency_features, TIME_LENGTH

            pitch = cond[:, 0]
            freq_feat = generate_frequency_features(pitch, TIME_LENGTH)

            x_hat = self.decoder([z_noisy, cond, freq_feat])
            x_hat = x_hat[:, :TIME_LENGTH, :]

            x_target = tf.squeeze(x, axis=-1)
            x_hat_sq = tf.squeeze(x_hat, axis=-1)

            # æå¤±è¨ˆç®—
            recon = tf.reduce_mean(tf.square(x_target - x_hat_sq))

            # â˜…å¯¾ç­–2: Free Bits KL
            kl_free_bits = self.compute_free_bits_kl(z_mean, z_logvar)

            # é€šå¸¸ã®KLã‚‚è¨ˆç®—ï¼ˆç›£è¦–ç”¨ï¼‰
            kl_standard = -0.5 * tf.reduce_mean(
                1 + z_logvar - tf.square(z_mean) - tf.exp(z_logvar)
            )

            # â˜…å¯¾ç­–3: Mutual Informationè¿½åŠ æå¤±
            # zã¨xã®ç›¸äº’æƒ…å ±é‡ã‚’æœ€å¤§åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            # ã“ã‚Œã¯ã‚ˆã‚Šé«˜åº¦ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ãªã®ã§ã€ã¾ãšã¯ Free Bits ã§è©¦ã™

            from loss import Loss

            stft_loss, mel_loss, diff_loss = Loss(
                x_target, x_hat_sq, fft_size=2048, hop_size=512
            )

            # â˜…å¯¾ç­–4: æ®µéšçš„ãªKLé‡ã¿
            kl_weight = self.compute_kl_weight_with_warmup()

            loss = (
                recon * 5.0
                + stft_loss * 10.0
                + mel_loss * 8.0
                + diff_loss * 2.0
                + kl_free_bits * kl_weight  # Free Bitsã‚’ä½¿ç”¨
            )

        grads = tape.gradient(loss, self.trainable_variables)
        grads, grad_norm = tf.clip_by_global_norm(grads, 5.0)
        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))

        # â˜…å¯¾ç­–5: zã®æ´»ç”¨åº¦ã‚’ç›£è¦–
        z_std = tf.reduce_mean(tf.math.reduce_std(z_mean, axis=1))
        # æŒ‡æ•°ç§»å‹•å¹³å‡ã§å¹³æ»‘åŒ–
        self.z_std_ema.assign(0.99 * self.z_std_ema + 0.01 * z_std)

        # â˜…å¯¾ç­–6: è­¦å‘Šã‚·ã‚¹ãƒ†ãƒ 
        # z_stdãŒå°ã•ããªã‚Šã™ããŸã‚‰KLé‡ã¿ã‚’ä¸‹ã’ã‚‹ï¼ˆè‡ªå‹•èª¿æ•´ï¼‰
        should_reduce_kl = tf.cond(
            self.z_std_ema < 0.05, lambda: True, lambda: False
        )

        return {
            "loss": loss,
            "recon": recon,
            "stft": stft_loss,
            "mel": mel_loss,
            "kl_standard": kl_standard,
            "kl_free_bits": kl_free_bits,
            "kl_weight": kl_weight,
            "z_std": z_std,
            "z_std_ema": self.z_std_ema,
            "grad_norm": grad_norm,
            "collapse_warning": tf.cast(should_reduce_kl, tf.float32),
        }

    def sample_z(self, z_mean, z_logvar):
        """
        Reparameterization trick
        """
        eps = tf.random.normal(shape=tf.shape(z_mean))
        return z_mean + tf.exp(0.5 * z_logvar) * eps


# ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯: Collapseæ¤œå‡º
class CollapseDetectionCallback(tf.keras.callbacks.Callback):
    """
    å­¦ç¿’ä¸­ã«Posterior Collapseã‚’æ¤œå‡ºã—ã¦è­¦å‘Š
    """

    def __init__(self, threshold=0.05, patience=5):
        super().__init__()
        self.threshold = threshold
        self.patience = patience
        self.low_std_count = 0

    def on_epoch_end(self, epoch, logs=None):
        z_std = logs.get("z_std_ema", 1.0)

        if z_std < self.threshold:
            self.low_std_count += 1
            print(f"\nâš ï¸  WARNING: z_std={z_std:.4f} < {self.threshold}")
            print(
                f"   Posterior Collapse ã®å…†å€™ ({self.low_std_count}/{self.patience})"
            )

            if self.low_std_count >= self.patience:
                print("\nğŸš¨ CRITICAL: Posterior Collapse æ¤œå‡ºï¼")
                print("   æ¨å¥¨å¯¾ç­–:")
                print("   1. KLé‡ã¿ã‚’1/10ã«æ¸›ã‚‰ã™")
                print("   2. Free Bitsã‚’å¢—ã‚„ã™ (0.5 â†’ 1.0)")
                print("   3. å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹")
                print("   4. ã‚ˆã‚Šå¤šãã®Warmupã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½¿ã†\n")
        else:
            self.low_std_count = 0
            if epoch % 10 == 0:
                print(f"âœ“ z_std={z_std:.4f} - æ½œåœ¨å¤‰æ•°ã¯å¥å…¨ã§ã™")


# å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹
def train_with_anti_collapse():
    """
    Posterior Collapseå¯¾ç­–ã‚’æ–½ã—ãŸå­¦ç¿’
    """
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ï¼‰
    dataset = make_dataset_from_synth_csv("dataset.csv", batch_size=16)

    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    model = AntiCollapseCVAE()
    x_dummy, cond_dummy = next(iter(dataset))
    _ = model((x_dummy, cond_dummy), training=False)
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))

    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    callbacks = [
        CollapseDetectionCallback(threshold=0.05, patience=5),
        tf.keras.callbacks.ModelCheckpoint(
            "checkpoints/best_model.weights.h5",
            monitor="z_std_ema",
            mode="max",  # z_stdãŒå¤§ãã„æ–¹ãŒè‰¯ã„
            save_best_only=True,
            save_weights_only=True,
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="loss", factor=0.5, patience=10, min_lr=1e-6
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor="collapse_warning", patience=20, restore_best_weights=True
        ),
    ]

    # å­¦ç¿’å®Ÿè¡Œ
    history = model.fit(
        dataset,
        epochs=200,
        callbacks=callbacks,
    )

    return model


if __name__ == "__main__":
    print("=" * 60)
    print("Posterior Collapseå¯¾ç­–ç‰ˆ å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    print("\nä¸»ãªå¯¾ç­–:")
    print("1. Free Bits: å„æ¬¡å…ƒã§æœ€ä½é™ã®æƒ…å ±é‡ã‚’ä¿è¨¼")
    print("2. KL Warmup: æ®µéšçš„ã«KLæå¤±ã‚’å°å…¥")
    print("3. ãƒã‚¤ã‚ºæ³¨å…¥: ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’zã®å¤‰åŒ–ã«é ‘å¼·ã«")
    print("4. è‡ªå‹•ç›£è¦–: z_stdã‚’è¿½è·¡ã—ã¦è­¦å‘Š")
    print("5. é©å¿œçš„å­¦ç¿’: Collapseæ¤œå‡ºæ™‚ã«å­¦ç¿’ç‡ã‚’è‡ªå‹•èª¿æ•´")
    print("=" * 60)

    train_with_anti_collapse()
