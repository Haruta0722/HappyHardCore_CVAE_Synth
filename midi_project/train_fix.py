import tensorflow as tf
import numpy as np
import os
from model import TimeWiseCVAE, TIME_LENGTH
from create_datasets import make_dataset_from_synth_csv

# GPUãƒ¡ãƒ¢ãƒªè¨­å®š
gpus = tf.config.experimental.list_physical_devices("GPU")
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)


def create_callbacks(save_dir="weights"):
    """è¨“ç·´ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    os.makedirs(save_dir, exist_ok=True)

    callbacks = [
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ï¼ˆ10ã‚¨ãƒãƒƒã‚¯ã”ã¨ï¼‰
        tf.keras.callbacks.ModelCheckpoint(
            filepath=os.path.join(save_dir, "epoch_{epoch:03d}.weights.h5"),
            save_weights_only=True,
            save_freq="epoch",
            period=10,
            verbose=1,
        ),
        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        tf.keras.callbacks.ModelCheckpoint(
            filepath=os.path.join(save_dir, "best_model.weights.h5"),
            save_weights_only=True,
            save_best_only=True,
            monitor="loss",
            mode="min",
            verbose=1,
        ),
        # TensorBoard
        tf.keras.callbacks.TensorBoard(
            log_dir="logs",
            histogram_freq=0,
            write_graph=False,
            update_freq="epoch",
        ),
        # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor="loss",
            factor=0.5,
            patience=20,
            min_lr=1e-6,
            verbose=1,
        ),
        # Early Stoppingï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        tf.keras.callbacks.EarlyStopping(
            monitor="loss",
            patience=50,
            restore_best_weights=True,
            verbose=1,
        ),
        # ã‚«ã‚¹ã‚¿ãƒ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå­¦ç¿’çŠ¶æ³ã®è©³ç´°è¡¨ç¤º
        DetailedLogger(),
        # â˜…æ–°è¦: KLæå¤±ã®ç›£è¦–ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        KLMonitor(),
    ]

    return callbacks


class DetailedLogger(tf.keras.callbacks.Callback):
    """è©³ç´°ãªãƒ­ã‚°å‡ºåŠ›"""

    def on_epoch_end(self, epoch, logs=None):
        if logs is None:
            logs = {}

        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1} å®Œäº†")
        print(f"{'='*60}")
        print(f"Loss: {logs.get('loss', 0):.6f}")
        print(f"  - Recon: {logs.get('recon', 0):.6f}")
        print(f"  - STFT: {logs.get('stft', 0):.6f}")
        print(f"  - Mel: {logs.get('mel', 0):.6f}")
        print(
            f"  - KL: {logs.get('kl', 0):.6f} (weight: {logs.get('kl_weight', 0):.6f})"
        )
        print(f"Z stats:")
        print(f"  - std_ema: {logs.get('z_std_ema', 0):.6f}")
        print(f"  - grad_norm: {logs.get('grad_norm', 0):.6f}")
        print(f"{'='*60}\n")


class KLMonitor(tf.keras.callbacks.Callback):
    """
    â˜…æ–°è¦: KLæå¤±ã®ç›£è¦–ã¨è­¦å‘Š
    z=randomå•é¡Œã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    """

    def __init__(self):
        super().__init__()
        self.kl_history = []
        self.z_std_history = []

    def on_epoch_end(self, epoch, logs=None):
        if logs is None:
            logs = {}

        kl_loss = logs.get("kl", 0)
        z_std = logs.get("z_std_ema", 0)
        kl_weight = logs.get("kl_weight", 0)

        self.kl_history.append(kl_loss)
        self.z_std_history.append(z_std)

        # è­¦å‘Šãƒã‚§ãƒƒã‚¯
        warnings = []

        # KLæå¤±ãŒä½ã™ãã‚‹ï¼ˆposterior collapseï¼‰
        if epoch > 40 and kl_loss < 0.1:
            warnings.append(
                "âš ï¸  KLæå¤±ãŒä½ã™ãã¾ã™ã€‚Posterior collapseã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            )

        # zã®æ¨™æº–åå·®ãŒå°ã•ã™ãã‚‹
        if epoch > 40 and z_std < 0.3:
            warnings.append(
                "âš ï¸  Zã®æ¨™æº–åå·®ãŒå°ã•ã™ãã¾ã™ã€‚æ½œåœ¨ç©ºé–“ãŒä½¿ã‚ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            )

        # zã®æ¨™æº–åå·®ãŒå¤§ãã™ãã‚‹
        if z_std > 3.0:
            warnings.append("âš ï¸  Zã®æ¨™æº–åå·®ãŒå¤§ãã™ãã¾ã™ã€‚å­¦ç¿’ãŒä¸å®‰å®šã§ã™ã€‚")

        # KL weightãŒé©åˆ‡ã«å¢—åŠ ã—ã¦ã„ã‚‹ã‹
        if epoch == 30 and kl_weight < 0.00001:
            warnings.append("âš ï¸  KL weightã®å¢—åŠ ãŒé…ã™ãã¾ã™ã€‚")

        # è­¦å‘Šã‚’è¡¨ç¤º
        if warnings:
            print("\n" + "ğŸ” è¨ºæ–­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ".center(60, "="))
            for warning in warnings:
                print(warning)
            print("=" * 60 + "\n")

        # è‰¯å¥½ãªçŠ¶æ…‹ã‚’å ±å‘Š
        if (
            epoch > 60
            and 0.5 < kl_loss < 5.0
            and 0.5 < z_std < 2.0
            and kl_weight > 0.0001
        ):
            print("\nâœ… æ½œåœ¨å¤‰æ•°ã®å­¦ç¿’ãŒè‰¯å¥½ã§ã™ï¼")


class SynthesisTest(tf.keras.callbacks.Callback):
    """
    â˜…æ–°è¦: å®šæœŸçš„ã«åˆæˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    z=0ã¨z=randomã§ã®éŸ³å£°åˆæˆã‚’ãƒ†ã‚¹ãƒˆ
    """

    def __init__(self, test_interval=10, output_dir="test_outputs"):
        super().__init__()
        self.test_interval = test_interval
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def on_epoch_end(self, epoch, logs=None):
        if (epoch + 1) % self.test_interval != 0:
            return

        print(f"\nğŸµ åˆæˆãƒ†ã‚¹ãƒˆ (Epoch {epoch+1}) ".center(60, "="))

        # ãƒ†ã‚¹ãƒˆç”¨æ¡ä»¶: [pitch, screech, acid, pluck]
        test_conditions = [
            ([0.5, 0.0, 0.0, 1.0], "pluck"),
            ([0.3, 0.0, 1.0, 0.0], "acid"),
            ([0.7, 1.0, 0.0, 0.0], "screech"),
        ]

        for cond_values, timbre_name in test_conditions:
            cond = tf.constant([cond_values], dtype=tf.float32)

            # z=0ã§ãƒ†ã‚¹ãƒˆ
            z_zero = tf.zeros((1, self.model.decoder.input[0].shape[1], 64))
            try:
                output_zero = self.model.decoder([z_zero, cond], training=False)
                rms_zero = tf.sqrt(tf.reduce_mean(tf.square(output_zero)))
                status_zero = "âœ“" if rms_zero > 0.01 else "âœ—"
                print(
                    f"  {timbre_name} (z=0): RMS={rms_zero:.4f} {status_zero}"
                )
            except Exception as e:
                print(f"  {timbre_name} (z=0): ã‚¨ãƒ©ãƒ¼ - {str(e)}")

            # z=randomã§ãƒ†ã‚¹ãƒˆ
            z_random = tf.random.normal(
                (1, self.model.decoder.input[0].shape[1], 64)
            )
            try:
                output_random = self.model.decoder(
                    [z_random, cond], training=False
                )
                rms_random = tf.sqrt(tf.reduce_mean(tf.square(output_random)))
                status_random = "âœ“" if rms_random > 0.01 else "âœ—"
                print(
                    f"  {timbre_name} (z=random): RMS={rms_random:.4f} {status_random}"
                )
            except Exception as e:
                print(f"  {timbre_name} (z=random): ã‚¨ãƒ©ãƒ¼ - {str(e)}")

        print("=" * 60 + "\n")


def main():
    print("=" * 60)
    print("æ”¹å–„ç‰ˆ DDSPé¢¨ãƒ¢ãƒ‡ãƒ« è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)

    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    BATCH_SIZE = 16
    EPOCHS = 200
    LEARNING_RATE = 1e-4

    print(f"\nè¨­å®š:")
    print(f"  Batch size: {BATCH_SIZE}")
    print(f"  Epochs: {EPOCHS}")
    print(f"  Learning rate: {LEARNING_RATE}")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    print("\n[1] ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ä¸­...")
    train_dataset = make_dataset_from_synth_csv(
        "dataset.csv",
        batch_size=BATCH_SIZE,
    )
    train_dataset = train_dataset.repeat()

    # 1ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’è¨ˆç®—
    steps_per_epoch = 87  # ã‚ãªãŸã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦å¤‰æ›´

    print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†")
    print(f"  Steps per epoch: {steps_per_epoch}")

    # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
    print("\n[2] ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...")
    model = TimeWiseCVAE(steps_per_epoch=steps_per_epoch)

    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
    optimizer = tf.keras.optimizers.Adam(
        learning_rate=LEARNING_RATE,
        clipnorm=1.0,  # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
    )
    model.compile(optimizer=optimizer)

    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ“ãƒ«ãƒ‰
    dummy_x = tf.zeros((1, TIME_LENGTH, 1))
    dummy_cond = tf.zeros((1, 4))
    _ = model((dummy_x, dummy_cond), training=False)

    print("âœ“ ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†")
    print("\n[Encoder]")
    model.encoder.summary()
    print("\n[Decoder]")
    model.decoder.summary()

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¡¨ç¤º
    total_params = sum([tf.size(v).numpy() for v in model.trainable_variables])
    print(f"\nç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")

    # â˜…æ”¹å–„ç‚¹ã®ç¢ºèª
    print("\n" + "=" * 60)
    print("æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ:")
    print("=" * 60)
    print("âœ“ KL warmup: 30ã‚¨ãƒãƒƒã‚¯ï¼ˆå¾“æ¥: 20ï¼‰")
    print("âœ“ KL rampup: 60ã‚¨ãƒãƒƒã‚¯ï¼ˆå¾“æ¥: 50ï¼‰")
    print("âœ“ KL target: 0.0003ï¼ˆå¾“æ¥: 0.0005ï¼‰")
    print("âœ“ Free bits: 1.0ï¼ˆå¾“æ¥: 0.8ï¼‰")
    print("âœ“ z_logvaråˆæœŸå€¤: -2.0ï¼ˆå¾“æ¥: -3.0ï¼‰")
    print("âœ“ éŸ³è‰²ç‰¹æ€§ã‚’condã‹ã‚‰ç›´æ¥ç”Ÿæˆ")
    print("âœ“ screechãƒã‚¤ã‚ºæ¯”: 0.3ï¼ˆå¾“æ¥: 0.6ï¼‰")
    print("=" * 60)

    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
    print("\n[3] ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š...")
    callbacks = create_callbacks()
    # â˜…æ–°è¦: åˆæˆãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿½åŠ 
    callbacks.append(SynthesisTest(test_interval=10))

    print("âœ“ ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šå®Œäº†")
    print("  - ModelCheckpoint (10ã‚¨ãƒãƒƒã‚¯ã”ã¨)")
    print("  - Best model checkpoint")
    print("  - TensorBoard")
    print("  - ReduceLROnPlateau")
    print("  - EarlyStopping")
    print("  - DetailedLogger")
    print("  - KLMonitor (æ–°è¦)")
    print("  - SynthesisTest (æ–°è¦)")

    # è¨“ç·´é–‹å§‹
    print("\n[4] è¨“ç·´é–‹å§‹")
    print("=" * 60)
    print("å­¦ç¿’ä¸­ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ:")
    print("  1. z_std_ema ãŒ 0.5-2.0 ã®ç¯„å›²ã«åæŸã™ã‚‹ã‹")
    print("  2. KLæå¤±ãŒå¾ã€…ã«å¢—åŠ ã™ã‚‹ã‹ï¼ˆ0.5-5.0ãŒç›®æ¨™ï¼‰")
    print("  3. 30ã‚¨ãƒãƒƒã‚¯ä»¥é™ã§KL weightãŒå¢—åŠ ã—å§‹ã‚ã‚‹ã‹")
    print("  4. åˆæˆãƒ†ã‚¹ãƒˆã§z=0ã¨z=randomã®ä¸¡æ–¹ã§éŸ³ãŒå‡ºã‚‹ã‹")
    print("=" * 60 + "\n")

    try:
        history = model.fit(
            train_dataset,
            epochs=EPOCHS,
            steps_per_epoch=steps_per_epoch,
            callbacks=callbacks,
            verbose=1,
        )

        print("\n" + "=" * 60)
        print("è¨“ç·´å®Œäº†ï¼")
        print("=" * 60)

        # æœ€çµ‚çµ±è¨ˆ
        final_loss = history.history["loss"][-1]
        final_recon = history.history["recon"][-1]
        final_kl = history.history["kl"][-1]
        final_z_std = history.history["z_std_ema"][-1]

        print(f"\næœ€çµ‚çµæœ:")
        print(f"  Loss: {final_loss:.6f}")
        print(f"  Reconstruction: {final_recon:.6f}")
        print(f"  KL: {final_kl:.6f}")
        print(f"  Z std EMA: {final_z_std:.6f}")

        # æœ€è‰¯ã‚¨ãƒãƒƒã‚¯ã®æƒ…å ±
        best_epoch = np.argmin(history.history["loss"]) + 1
        best_loss = np.min(history.history["loss"])
        print(f"\næœ€è‰¯ã‚¨ãƒãƒƒã‚¯: {best_epoch}")
        print(f"  Loss: {best_loss:.6f}")

        # å­¦ç¿’ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
        print("\n" + "=" * 60)
        print("å­¦ç¿’ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯:")
        print("=" * 60)

        checks = []
        if 0.5 <= final_z_std <= 2.0:
            checks.append("âœ“ Zæ¨™æº–åå·®ãŒé©åˆ‡ãªç¯„å›²ã§ã™")
        else:
            checks.append(f"âœ— Zæ¨™æº–åå·®ãŒç¯„å›²å¤–ã§ã™ ({final_z_std:.2f})")

        if 0.5 <= final_kl <= 10.0:
            checks.append("âœ“ KLæå¤±ãŒé©åˆ‡ãªç¯„å›²ã§ã™")
        else:
            checks.append(f"âœ— KLæå¤±ãŒç¯„å›²å¤–ã§ã™ ({final_kl:.2f})")

        if final_recon < 0.01:
            checks.append("âœ“ å†æ§‹æˆèª¤å·®ãŒååˆ†å°ã•ã„ã§ã™")
        else:
            checks.append(f"âš ï¸  å†æ§‹æˆèª¤å·®ãŒå¤§ãã„ã§ã™ ({final_recon:.4f})")

        for check in checks:
            print(check)

        print("=" * 60)

    except KeyboardInterrupt:
        print("\nè¨“ç·´ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        print("æœ€å¾Œã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")

    print("\nä¿å­˜å ´æ‰€:")
    print("  weights/best_model.weights.h5 - æœ€è‰¯ãƒ¢ãƒ‡ãƒ«")
    print("  weights/epoch_XXX.weights.h5 - å„ã‚¨ãƒãƒƒã‚¯ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ")
    print("  logs/ - TensorBoardãƒ­ã‚°")
    print("  test_outputs/ - åˆæˆãƒ†ã‚¹ãƒˆå‡ºåŠ›")

    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. TensorBoardã§è¨“ç·´æ›²ç·šã‚’ç¢ºèª")
    print("     $ tensorboard --logdir=logs")
    print("  2. ä»¥ä¸‹ã®æŒ‡æ¨™ã‚’ç¢ºèª:")
    print("     - z_std_ema: 0.5-2.0ã®ç¯„å›²ã«ã‚ã‚‹ã‹")
    print("     - kl: 0.5-5.0ã®ç¯„å›²ã§æ¨ç§»ã—ã¦ã„ã‚‹ã‹")
    print("     - kl_weight: 60ã‚¨ãƒãƒƒã‚¯ä»¥é™ã§0.0003ã«é”ã—ã¦ã„ã‚‹ã‹")
    print("  3. inference_improved.py ã§æ¨è«–ãƒ†ã‚¹ãƒˆ")
    print("     - z=0ã§pluckã®æ€¥é€Ÿæ¸›è¡°ã‚’ç¢ºèª")
    print("     - z=0ã§acidã®ã†ã­ã‚Šã‚’ç¢ºèª")
    print("     - z=0ã§screechã®ãƒã‚¤ã‚ºé‡ã‚’ç¢ºèª")
    print("     - z=randomã§éŸ³ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã‚‹ã‹ç¢ºèª")
    print("=" * 60)


if __name__ == "__main__":
    main()
